{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое занятие №4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимые сегодня библиотеки"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch\n",
    "* timm\n",
    "* scikit-learn\n",
    "* pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение нейронных сетей"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет собран из двух наборов:\n",
    "* [Cats, dogs and birds](https://universe.roboflow.com/image-classification-y0lsy/cats--dogs-and-birds)\n",
    "* [Classifier_Animals](https://universe.roboflow.com/rna-class/classifier_animals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам датасет можно скачать по [ссылке](https://mega.nz/file/zBBhmSCR#i6GNK9IP2BZhPS_5ayBUw1cdz-ozXXNVTvva7Vc3cPQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, data_path, labels, input_channels=3, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.input_channels = input_channels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.labels.iloc[idx, 0]\n",
    "        target = self.labels.iloc[idx, 1]\n",
    "\n",
    "        img = Image.open(os.path.join(self.data_path, fileName))\n",
    "        if self.input_channels == 3:\n",
    "            img = img.convert('RGB')\n",
    "        else:\n",
    "            img = img.convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, train_transform, val_transform, input_channels=3):\n",
    "    path =  os.path.dirname(os.path.abspath(data_path))\n",
    "    train_labels = pd.read_csv(data_path, sep=';')\n",
    "\n",
    "    train_labels, valid_labels = train_test_split(train_labels,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=random.randint(1, 10000))\n",
    "\n",
    "    train_labels = train_labels.reset_index(drop=True)\n",
    "    valid_labels = valid_labels.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = ClsDataset(path, train_labels, input_channels, train_transform)\n",
    "    val_dataset = ClsDataset(path, valid_labels, input_channels, val_transform)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].contiguous().view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0/batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        self.val = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(backbone, device, train_loader, criterion, optimizer):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    backbone.train()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        target = target.type(torch.LongTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = backbone(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # measure accuracy\n",
    "        acc = accuracy(output, target)\n",
    "        \n",
    "        # record loss and accuracy\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        accs.update(acc[0], data.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цикл валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(backbone, device, val_loader, criterion):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to val mode\n",
    "    backbone.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(val_loader):\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = backbone(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # measure accuracy\n",
    "            acc = accuracy(output, target)\n",
    "            \n",
    "            # record loss and accuracy\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            accs.update(acc[0], data.size(0))\n",
    "\n",
    "    return losses.avg, accs.avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация конфига для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size'    : 16,\n",
    "    'total_epochs'  : 101,\n",
    "    'save_epoch'    : 10,\n",
    "    'learning_rate' : 0.001,\n",
    "    'data_path'     : './train_data/train/list.csv', # путь до csv-файла\n",
    "    'save_path'     : './weights', # путь куда сохранять модельки\n",
    "    'num_classes'   : 4,\n",
    "    'input_size'    : 224,\n",
    "    'input_channels': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config['save_path']):\n",
    "    os.mkdir(config['save_path'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор девайса для обучения: cpu/gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "print('Device is', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация начальных состояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "random_seed = round(time.time() * 1000)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искажения для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Типы](https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) искажений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms for input images\n",
    "normalize = transforms.Normalize(mean=[0.498, 0.498, 0.498],\n",
    "                                std=[0.502, 0.502, 0.502])\n",
    "\n",
    "if config['input_channels'] == 1:\n",
    "    normalize = transforms.Normalize(mean=[0.498], std=[0.502])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ColorJitter(brightness=.1, hue=.1),\n",
    "    transforms.Resize((config['input_size'], config['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config['input_size'], config['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_data(config['data_path'], train_transform, val_transform, config['input_channels'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=use_gpu,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=use_gpu,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print('Train num = {}'.format(len(train_dataset)))\n",
    "print('Val val = {}'.format(len(val_dataset)))\n",
    "\n",
    "print('Train batch = {}'.format(len(train_loader)))\n",
    "print('Val batch = {}'.format(len(val_loader)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=config['num_classes'], in_chans=config['input_channels']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(backbone,input_size = (config['batch_size'], config['input_channels'], config['input_size'], config['input_size']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрещаем изменение градиентов у всех слоёв, кроме финального"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_pretrained_layers(model):\n",
    "    for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.classifier.weight.requires_grad = True\n",
    "    model.classifier.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_pretrained_layers(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backbone.bn1.weight.requires_grad)\n",
    "print(backbone.classifier.weight.requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация остальных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(params=backbone.parameters(), lr=config['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение весов модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, state, epoch, tag=''):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    filename = os.path.join(save_path, \"{}checkpoint-{:06}.pth.tar\".format(tag, epoch))\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start train')\n",
    "log = {\"epoch\": [], \"train_loss\": [],  \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in (range(config['total_epochs'])):\n",
    "    train_loss, train_acc = train(backbone, device, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = val(backbone, device, val_loader, criterion)\n",
    "\n",
    "    if epoch % config['save_epoch'] == 0:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': backbone.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            'acc': val_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'criterion': criterion.state_dict(),\n",
    "            'input_shape': (config['input_size'], config['input_size'], config['input_channels']),\n",
    "            'num_classes': config['num_classes']\n",
    "        }\n",
    "        save_checkpoint(config['save_path'], state, epoch, '')\n",
    "\n",
    "    log['epoch'].append(epoch)\n",
    "    log['train_loss'].append(train_loss)\n",
    "    log['val_loss'].append(val_loss)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.plot(log['epoch'], log['train_loss'], label='train')\n",
    "    plt.plot(log['epoch'], log['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    line = '[{}/{}]\\t\\tLR: {:.2}\\t\\tTrain loss: {:.3}\\t\\tTrain acc: {:.3}\\t\\tVal loss: {:.3}\\t\\tVal acc: {:.3}'.format(\n",
    "    epoch,\n",
    "    config['total_epochs']-1,\n",
    "    get_lr(optimizer),\n",
    "    train_loss,\n",
    "    train_acc,\n",
    "    val_loss,\n",
    "    val_acc\n",
    "    )\n",
    "    print(line)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print('Stop train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Bird', 'Cat', 'Dog', 'Lion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './weights/checkpoint-000100.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(model_path, device)\n",
    "inf_backbone = timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=config['num_classes']).to(device)\n",
    "inf_backbone.load_state_dict(checkpoint['state_dict'])\n",
    "inf_backbone.eval()\n",
    "\n",
    "test_data_path = r'.\\train_data\\test\\dog\\Cachorro72_jpg.rf.1f37f27288e95c32be7f382fc24388cd.jpg'\n",
    "pil_img = Image.open(test_data_path).convert('RGB')\n",
    "img = val_transform(pil_img)\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, 0)\n",
    "\n",
    "data = torch.tensor(img, dtype=torch.float32, device=device)\n",
    "data = data.to(device)\n",
    "output = inf_backbone(data)\n",
    "soft_output = torch.softmax(output, dim=-1)\n",
    "_, predicted = torch.max(soft_output.data, 1)\n",
    "confidence = soft_output[0][predicted[0]]\n",
    "predicted = predicted.to(device).cpu().detach().numpy()[0]\n",
    "\n",
    "print('Class: {}\\t Confidence: {}'.format(\n",
    "    classes[predicted],\n",
    "    confidence\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
